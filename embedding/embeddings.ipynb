{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirtan_patel/Documents/SproutsAI/vent/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shamimhasan8/resume-vs-job-description-matching-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927k/927k [00:00<00:00, 4.37MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../dataset/1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download resume dataset\n",
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "download_path = kagglehub.dataset_download(\"shamimhasan8/resume-vs-job-description-matching-dataset\")\n",
    "target_folder = \"../dataset\"\n",
    "\n",
    "shutil.move(download_path, target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/surendra365/recruitement-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.58M/1.58M [00:00<00:00, 1.91MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../dataset/2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "download_path = kagglehub.dataset_download(\"surendra365/recruitement-dataset\")\n",
    "\n",
    "shutil.move(download_path, target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirtan_patel/Documents/SproutsAI/vent/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# use gpu is possible\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# load model on CPU first (to avoid meta tensor error)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"../dataset/resume_job_matching_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# normalize similarity score (1-5) linearly from 0 to 1\n",
    "df['normal_score'] = (df['match_score'] - 1) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path2 = \"../dataset/job_applicant_dataset.csv\"\n",
    "df2 = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Job Applicant Name  Age  Gender             Race   Ethnicity  \\\n",
      "0          Daisuke Mori   29    Male  Mongoloid/Asian  Vietnamese   \n",
      "1        Taichi Shimizu   31    Male  Mongoloid/Asian    Filipino   \n",
      "2          Sarah Martin   46  Female  White/Caucasian       Dutch   \n",
      "3          Keith Hughes   43    Male    Negroid/Black   Caribbean   \n",
      "4           James Davis   49    Male  White/Caucasian     English   \n",
      "...                 ...  ...     ...              ...         ...   \n",
      "9995      Jada Williams   30  Female    Negroid/Black    Ghanaian   \n",
      "9996       Jaden Carter   52    Male    Negroid/Black    Nigerian   \n",
      "9997         Mia Foster   25  Female  White/Caucasian      German   \n",
      "9998       Stella Green   51  Female  White/Caucasian       Irish   \n",
      "9999        Ryo Nishida   46    Male  Mongoloid/Asian        Thai   \n",
      "\n",
      "                                                 Resume             Job Roles  \\\n",
      "0     Proficient in Injury Prevention, Motivation, N...         Fitness Coach   \n",
      "1     Proficient in Healthcare, Pharmacology, Medica...             Physician   \n",
      "2     Proficient in Forecasting, Financial Modelling...     Financial Analyst   \n",
      "3     Proficient in Budgeting, Supply Chain Optimiza...  Supply Chain Manager   \n",
      "4     Proficient in Logistics, Negotiation, Procurem...  Supply Chain Manager   \n",
      "...                                                 ...                   ...   \n",
      "9995  Proficient in Biology, Regulatory Compliance, ...   Biomedical Engineer   \n",
      "9996  Proficient in Communication, Teamwork, Lesson ...               Teacher   \n",
      "9997  Proficient in Medical Terminology, Critical Th...             Physician   \n",
      "9998  Proficient in Exercise Programming, Motivation...         Fitness Coach   \n",
      "9999  Proficient in Content Strategy, Copywriting, C...        Content Writer   \n",
      "\n",
      "                                        Job Description  Best Match  \n",
      "0      A Fitness Coach is responsible for helping cl...           0  \n",
      "1     Diagnose and treat illnesses, prescribe medica...           0  \n",
      "2     As a Financial Analyst, you will be responsibl...           0  \n",
      "3     A Supply Chain Manager oversees the entire sup...           1  \n",
      "4     A Supply Chain Manager oversees the entire sup...           1  \n",
      "...                                                 ...         ...  \n",
      "9995  A Biomedical Engineer designs and develops med...           0  \n",
      "9996  A Teacher shapes the future of students by del...           0  \n",
      "9997  Diagnose and treat illnesses, prescribe medica...           0  \n",
      "9998   A Fitness Coach is responsible for helping cl...           1  \n",
      "9999  As a Content Writer, you will create written m...           0  \n",
      "\n",
      "[10000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "9995    1\n",
      "9996    0\n",
      "9997    0\n",
      "9998    0\n",
      "9999    1\n",
      "Name: normal_score, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# make sure values are from 0 - 1\n",
    "import numpy as np\n",
    "df['normal_score'].describe()\n",
    "df['normal_score'] = np.where(df['normal_score'] >= 0.5, 1, 0)\n",
    "print(df['normal_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine 2 datasets\n",
    "df2_renamed = df2.rename(columns={\n",
    "    'Best Match': 'normal_score',\n",
    "    'Job Description': 'job_description',\n",
    "    \"Resume\" : 'resume'\n",
    "})\n",
    "\n",
    "columns_to_keep = ['job_description', 'resume', 'normal_score']\n",
    "df2_sub = df2_renamed[columns_to_keep].copy()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in df2_sub.columns:\n",
    "        df2_sub.loc[:, col] = pd.NA\n",
    "\n",
    "# Now concatenate\n",
    "df_combined = pd.concat([df, df2_sub], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>resume</th>\n",
       "      <th>match_score</th>\n",
       "      <th>normal_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst needed with experience in SQL, Ex...</td>\n",
       "      <td>Experienced professional skilled in SQL, Power...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist needed with experience in Stati...</td>\n",
       "      <td>Experienced professional skilled in Python, De...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Engineer needed with experience in Sy...</td>\n",
       "      <td>Experienced professional skilled in wait, Git,...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML Engineer needed with experience in Python, ...</td>\n",
       "      <td>Experienced professional skilled in return, De...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Engineer needed with experience in RE...</td>\n",
       "      <td>Experienced professional skilled in REST APIs,...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>A Biomedical Engineer designs and develops med...</td>\n",
       "      <td>Proficient in Biology, Regulatory Compliance, ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>A Teacher shapes the future of students by del...</td>\n",
       "      <td>Proficient in Communication, Teamwork, Lesson ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Diagnose and treat illnesses, prescribe medica...</td>\n",
       "      <td>Proficient in Medical Terminology, Critical Th...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>A Fitness Coach is responsible for helping cl...</td>\n",
       "      <td>Proficient in Exercise Programming, Motivation...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>As a Content Writer, you will create written m...</td>\n",
       "      <td>Proficient in Content Strategy, Copywriting, C...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_description  \\\n",
       "0      Data Analyst needed with experience in SQL, Ex...   \n",
       "1      Data Scientist needed with experience in Stati...   \n",
       "2      Software Engineer needed with experience in Sy...   \n",
       "3      ML Engineer needed with experience in Python, ...   \n",
       "4      Software Engineer needed with experience in RE...   \n",
       "...                                                  ...   \n",
       "19995  A Biomedical Engineer designs and develops med...   \n",
       "19996  A Teacher shapes the future of students by del...   \n",
       "19997  Diagnose and treat illnesses, prescribe medica...   \n",
       "19998   A Fitness Coach is responsible for helping cl...   \n",
       "19999  As a Content Writer, you will create written m...   \n",
       "\n",
       "                                                  resume match_score  \\\n",
       "0      Experienced professional skilled in SQL, Power...           4   \n",
       "1      Experienced professional skilled in Python, De...           4   \n",
       "2      Experienced professional skilled in wait, Git,...           5   \n",
       "3      Experienced professional skilled in return, De...           4   \n",
       "4      Experienced professional skilled in REST APIs,...           5   \n",
       "...                                                  ...         ...   \n",
       "19995  Proficient in Biology, Regulatory Compliance, ...        <NA>   \n",
       "19996  Proficient in Communication, Teamwork, Lesson ...        <NA>   \n",
       "19997  Proficient in Medical Terminology, Critical Th...        <NA>   \n",
       "19998  Proficient in Exercise Programming, Motivation...        <NA>   \n",
       "19999  Proficient in Content Strategy, Copywriting, C...        <NA>   \n",
       "\n",
       "       normal_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "19995             0  \n",
       "19996             0  \n",
       "19997             0  \n",
       "19998             1  \n",
       "19999             0  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # collapse multiple spaces/newlines into a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-z0-9\\s.,\\-+#/]', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['job_description'] = df_combined['job_description'].apply(clean_text)\n",
    "df_combined['resume'] = df_combined['resume'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InputExample> label: 1, texts: experienced professional skilled in python, deep learning, mr, our, nlp, machine learning, hair, pandas. senior such scene prepare soon last remember. general word what worry week responsibility. attack half scene thought push be.; data scientist needed with experience in statistics, pandas, sql, machine learning, nlp, deep learning, python. unit resource none quickly second interesting really end. across price book similar song give. black seem reach deep.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "# create inputexample objects\n",
    "examples = []\n",
    "for _, row in df_combined.iterrows():\n",
    "    examples.append(\n",
    "        InputExample(texts=[row['resume'], row['job_description']], label=row['normal_score'])\n",
    "    )\n",
    "\n",
    "print(examples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 12:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.160600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.154900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=8)\n",
    "train_loss = CosineSimilarityLoss(model=model)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=2,\n",
    "    warmup_steps= len(train_dataloader) * 0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/kirtan_patel/Documents/SproutsAI/model/all_minilm_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
